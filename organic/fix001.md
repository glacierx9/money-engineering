# WOS docuram issues

- _on_cycle_passed usage
- copy_to_sv and from_sv usage
- visualization chaos
- bar_index in uout.json
- bar_since_start issue
- create_project's uout.json securities should be 'rb' not 'rb<00>'
- add a new tool to let the indicator go live.
    - Do backtest from the earliest to the most recent time
    - Resume the backtest from the a short time before the most recent time(10 days or so), this time uses overwrite=False mode
    - Go live
    -
    
## `copy_to_sv` and `from_sv`

### Inversed pair of functions

I found a very critical misunderstanding about `copy_to_sv`, `to_sv` and `from_sv`. 

`to_sv` and `from_sv` are a pair of inversed functions, now the documenation of sv_objects are misleading and not clear.

For example, if we have a vector field `emas` of double of fixed length 3. However, when we implement the python script, we want to manipulate the vector field as 3 different double fields.

- `ema_1`
- `ema_2`
- `ema_3`

We should deal with the serialization/deserialization as below:

```python
def to_sv(self):
    self.emas = [self.ema_1, self.ema_2, self.ema_3]
    return super().to_sv()

def from_sv(self, sv):
    super().from_sv(sv)
    self.ema_1, self.ema_2, self.ema_3 = self.emas
```

### Correct way of reconciling

- from_sv should cache the incoming bar to some object-wise variable(field)
- from_sv should only be called after `_on_cycle_pass` is done
- `_from_sv` should be defined as to restore from the from_sv cached bar object(or we can restore the bar object to the variable in from_sv)
- in `overwrite=False` mode, we will always use `_from_sv` to restore while in the opposite case, we should only do this before initialization is done
- initialization means all needed input is ready for continue calculating the indicator for output, usually we need N incoming bar cycles where N is $max(len(self.queue_parameters))$ where queue_parameters is instances of local field stores the dependencies for calculation in deque.
- remember to set the local cache object to None after each cycle
- when the calculation is ready from initialization and a cycle passed

```python
    def from_sv(self, sv: pc.StructValue):
        """Deserialize state from StructValue"""
        self.latest_sv = sv
    def _from_sv(self, sv: pc.StructValue):
        """Internal deserialization helper"""
        super().from_sv(sv)        
    def ready_to_serialize(self) -> bool:
        """Determine if state should be serialized"""
        return self.initialized
    def on_bar(self, bar: pc.StructValue) -> List[pc.StructValue]:
        ret = []  # ALWAYS return list
        # Extract metadata
        market = bar.get_market()
        code = bar.get_stock_code()
        tm = bar.get_time_tag()
        ns = bar.get_namespace()
        meta_id = bar.get_meta_id()

        # Handle cycle boundaries
        if self.timetag is None:
            self.timetag = tm

        if self.timetag < tm:
            # New cycle - process previous cycle's data
            self._on_cycle_pass(tm)
            if (not self.initialized or not overwrite) and self.latest_sv is not None:
                self._from_sv(self.latest_sv)
            # Serialize state if ready
            if self.ready_to_serialize():
                if not overwrite:
                    self._reconcile()
                ret.append(self.copy_to_sv())

            # Update for next cycle
            self.timetag = tm
            self.bar_since_start += 1
            self.bar_index += 1
            
            if self.bar_since_start >= MAX_BAR_REBUILD:
                self.initialized = True
            self.latest_sv = None         
        if self.hsindex.namespace == ns and self.hsindex.meta_id == meta_id:
            if code == b'rb<00>':
                self.hsindex.market = market
                self.hsindex.code = code
                self.hsindex.granularity = bar.get_granularity()
                self.hsindex.from_sv(bar)
        if self.meta_id == meta_id and self.namespace == ns and not self.initialized:
            self.from_sv(bar)
```
- 


## Package names and path

We use the local path to debug before. So we used to see this coding style for the old linker projects.

```python
# Import base extractor for subclassing
try:
    from WallE.sqsm.extractor import Extractor, FeatureLoader
except ImportError:
    from sqsm.extractor import Extractor, FeatureLoader
```

This is really bad. For the latest available packages have been distributed, you can refer to export_walle.py(/workspaces/wolverine-indicators/AI/Wall-E/export_walle.py).

So there we should always write like this:

```python
from WallE.sqsm.extractor import Extractor, FeatureLoader
```

## Time

The standard time comes with the StructValue instance is in ms since epoch. We have a rich set of APIs to work with this format of time. You can refer to pycaitlynutils3.py(/home/wolverine/bin/running/pycaitlynutils3.py). 

So the timetag comes with the bar is in this format. When we want to use the time of other format, for example, when we want to talk with the inference server, the current_time will be in YYYYmmddHHMMSS, in this case, we should convert it properly.

## _on_cycle_pass

### self.timetag and self.timetag_

We DON'T need self.timetag_ at all. self.timetag is defined in /home/wolverine/bin/running/pycaitlynts3.py. This is the only place we store the time for the StructValue instance.

We don't need the fallback code block to test if the self has this field or no if it's any subclass of sv_object.

### Data leakage

If we use member fields to store the imported indicator's sv, please do remember, all calculation is triggered at _on_cycle_pass. So please make sure all update with the incoming bar happened after _on_cycle_pass is executed. Otherwise there will be severe data leakage($X_t$ uses $Y_{t+1}$ to calculate). 

```python
def on_bar(self, bar):
    # ATTENTION: bar.timetag >= self.timetag, so bar can be one step ahead of the output

    tm = bar.get_time_tag()
    if self.timetag is None:
        self.timetag = tm
    
    if self.timetag < tm :
        self._on_cycle_pass(self.timetag)
        self.timetag = tm
    
    # From here on we can update local cached objects from the incoming data
    # Never update them before _on_cycle_pass is called
    # Otherwise data leakage will happen
    # ...
    # Bar can be the one step forward sv of the output as well.
    # To restore from the bar only after _on_cycle_pass is called
    if bar is instance of self's class and self is not initialized:
        self.from_sv(bar)
    ...

```

The besting timing for reconcile is for each time `_on_cycle_passed` is called. If by then we have the StructValue object of the past cycle from the server, we can reconcile the calculated data and the data from the server to guarantee the calculation is stable.

1. For any cycle t, if $X_t$ is the old frame from the server, we have to cache the received value from the function `from_sv` to a field 
2. When the cycle t passes, we will reconcile $X_t$ with the calculated value $Y_t$
3. After reconciling, we should set the field for caching to None

```python
    def on_bar(self, bar: pc.StructValue) -> List[pc.StructValue]:
        """
        Process incoming market data bars

        Returns:
            List of StructValue outputs (empty list if no output this cycle)
        """
        ret = []  # ALWAYS return list

        # Extract metadata
        market = bar.get_market()
        code = bar.get_stock_code()
        tm = bar.get_time_tag()
        ns = bar.get_namespace()
        meta_id = bar.get_meta_id()
        # incoming data for imported StructValues can ONLY be parsed here(before on_cycle_pass)
        # except the restoration(same meta's StructValues caching)
        if self.hsindex.namespace == ns and self.hsindex.meta_id == meta_id:
            if code == b'rb<00>':
                self.hsindex.market = market
                self.hsindex.code = code
                self.hsindex.granularity = bar.get_granularity()
                self.hsindex.from_sv(bar)
        # Handle cycle boundaries
        if self.timetag is None:
            self.timetag = tm

        if self.timetag < tm:
            # New cycle - process previous cycle's data
            self._on_cycle_pass(tm)
            if (not self.initialized or not overwrite) and self.latest_sv is not None:
                self._from_sv(self.latest_sv)
            # Serialize state if ready
            if self.ready_to_serialize():
                if not overwrite:
                    self._reconcile()
                ret.append(self.copy_to_sv())

            # Update for next cycle
            self.timetag = tm
            
            self.bar_since_start += 1 # this field will always be in memory only, don't persist it
            self.bar_index += 1 # this is global
            
            if self.bar_since_start >= MAX_BAR_REBUILD: # we will use the bar_since_start to help determine if the initialization is done
                self.initialized = True
            self.latest_sv = None 
        # This has to be at the end of on_bar, because the cycle pass can be triggered by the old frames from the server
        if self.meta_id == meta_id and self.namespace == ns and not self.initialized:
            self.from_sv(bar)
```

### Initialization

Sometimes, the calculation will use deque to store the historical frames. If we replay the data stream from the middle of the time, we can never guarantee the data consistency before the initialization is done.

To help us know when the initialization is done, we can use the in-memory variable bar_since_start which means how many cycles has passed since this run. This field should not be persistent.

Usually, $argmin_{bar_since_start} = max({sliding_window_len for all cached deques})$ is the mark of initialization is done 

